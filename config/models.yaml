models:
  - name: "distilbert-base-uncased-mnli"
    hf_name: "typeform/distilbert-base-uncased-mnli"
    task: "zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 125
      max_accuracy_drop: 0.015  # 1.5% max accuracy drop allowed
    benchmarks:
      - mnli
      - sentiment_analysis

  - name: "all-MiniLM-L6-v2"
    hf_name: "sentence-transformers/all-MiniLM-L6-v2"
    task: "semantic-similarity"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.01   # 1.0% max accuracy drop allowed
    benchmarks:
      - sts
      - semantic_similarity

  - name: "deberta-v3-base-mnli"
    hf_name: "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli"
    task: "zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 200
      max_accuracy_drop: 0.012  # 1.2% max accuracy drop allowed
    benchmarks:
      - mnli
      - zero_shot_clf

  # --- New NLI / zero-shot models (English) ---

  - name: "bart-large-mnli"
    hf_name: "facebook/bart-large-mnli"
    task: "zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 480
      max_accuracy_drop: 0.015
    benchmarks:
      - mnli
      - zero_shot_clf

  - name: "roberta-large-mnli"
    hf_name: "FacebookAI/roberta-large-mnli"
    task: "nli-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 450
      max_accuracy_drop: 0.012
    benchmarks:
      - mnli
      - snli

  - name: "modernbert-large-zeroshot-v2"
    hf_name: "MoritzLaurer/ModernBERT-large-zeroshot-v2.0"
    task: "zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 500
      max_accuracy_drop: 0.01
    benchmarks:
      - mnli
      - anli
      - zero_shot_clf


  # --- Smaller / efficient NLI models ---

  - name: "mobilebert-uncased-mnli"
    hf_name: "typeform/mobilebert-uncased-mnli"
    task: "zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - mnli

  - name: "deberta-v3-xsmall-mnli-binary"
    hf_name: "MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary"
    task: "binary-zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 100
      max_accuracy_drop: 0.015
    benchmarks:
      - mnli
      - anli
      - fever
      - zero_shot_clf_binary

  - name: "xtremedistil-l6-h256-nli-binary"
    hf_name: "MoritzLaurer/xtremedistil-l6-h256-mnli-fever-anli-ling-binary"
    task: "binary-zero-shot-classification"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - mnli
      - anli
      - fever
      - zero_shot_clf_binary

  # --- NLI-trained sentence embedder models ---

  - name: "all-mpnet-base-v2"
    hf_name: "sentence-transformers/all-mpnet-base-v2"
    task: "semantic-similarity"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 130
      max_accuracy_drop: 0.01
    benchmarks:
      - sts
      - semantic_similarity

  - name: "all-MiniLM-L12-v2"
    hf_name: "sentence-transformers/all-MiniLM-L12-v2"
    task: "semantic-similarity"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 50
      max_accuracy_drop: 0.01
    benchmarks:
      - sts
      - semantic_similarity

  - name: "microsoft/phi-2"
    hf_name: "microsoft/phi-2"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: microsoft/phi-2
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/phi-2

  - name: "Llama-2-7b"
    hf_name: "Llama-2-7b"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Llama-2-7b
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Llama-2-7b

  - name: "Mistral-7B"
    hf_name: "Mistral-7B"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Mistral-7B
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Mistral-7B

  - name: "Gemma-7b"
    hf_name: "Gemma-7b"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Gemma-7b
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Gemma-7b

  - name: "Phi-2"
    hf_name: "Phi-2"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Phi-2
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Phi-2

  - name: "Qwen-7B"
    hf_name: "Qwen-7B"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Qwen-7B
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Qwen-7B

  - name: "Falcon-7B"
    hf_name: "Falcon-7B"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: Falcon-7B
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/Falcon-7B

  - name: "MPT-7B"
    hf_name: "MPT-7B"
    task: "text-generation"
    quantization:
      bits: 8
      dtype: "int8"
      target_size_mb: 40
      max_accuracy_drop: 0.02
    benchmarks:
      - wikitext
      - lambada
    phi-2:
      name: MPT-7B
      type: causal-lm
      quantization: 4bit
      output_dir: models/mlx_converted/MPT-7B

text_models:
  - name: Llama-2-7b
    path: models/originals/text/Llama-2-7b
  - name: Mistral-7B
    path: models/originals/text/Mistral-7B
  - name: Gemma-7b
    path: models/originals/text/Gemma-7b
  - name: Phi-2
    path: models/originals/text/Phi-2
  - name: Qwen-7B
    path: models/originals/text/Qwen-7B
  - name: Falcon-7B
    path: models/originals/text/Falcon-7B
  - name: MPT-7B
    path: models/originals/text/MPT-7B

vision_models:
  - name: CLIP-ViT
    path: models/originals/vision/CLIP-ViT
  - name: DINOv2
    path: models/originals/vision/DINOv2
  - name: ViT-Base
    path: models/originals/vision/ViT-Base
  - name: ViT-Large
    path: models/originals/vision/ViT-Large
  - name: ResNet-50
    path: models/originals/vision/ResNet-50

audio_models:
  - name: whisper-medium
    path: models/originals/audio/whisper-medium
  - name: wav2vec2
    path: models/originals/audio/wav2vec2
  - name: SpeechT5
    path: models/originals/audio/SpeechT5
  - name: MMS-TTS
    path: models/originals/audio/MMS-TTS

multimodal_models:
  - name: FLAVA
    path: models/originals/multimodal/FLAVA
  - name: BLIP-2
    path: models/originals/multimodal/BLIP-2
  - name: LLaVA-7B
    path: models/originals/multimodal/LLaVA-7B
  - name: Kosmos-2
    path: models/originals/multimodal/Kosmos-2
